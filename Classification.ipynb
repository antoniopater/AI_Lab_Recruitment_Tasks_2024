{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-24T19:18:39.691950Z",
     "start_time": "2024-11-24T19:18:39.687148Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "czyszczenie modelu z kolumn o dużych brakach - jeden z celów EDA. WYczytałem taką zasadę gdzieś na Medium. że jeżeli kolumna ma powyżej 30% braków względem wszystkich danych to można ją wyrzucić - wprowadza dużo szumu w danych. Jednak końcowo ważna jest analiza, które z tych kolumn mogą mieć wartość predykcyjną.",
   "id": "2752d5208d81d28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T19:14:27.585727Z",
     "start_time": "2024-11-24T19:14:20.870022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class Predykcja:\n",
    "    def __init__(self,filename):\n",
    "        self.model = None\n",
    "        self.df = pd.read_csv(filename) \n",
    "        self.X, self.y, self.X_train, self.X_test, self.y_train, self.y_test = None,None,None,None, None, None\n",
    "    def EDA(self):\n",
    "        print(f\"Informacje o danych {self.df.info()}\")\n",
    "        print(f\"Shape {self.df.shape}\")\n",
    "        print(f\"Liczba braków w danych {self.df.isnull().sum()}\")\n",
    "    def kolumny_do_usuniecia(self):\n",
    "        ilosc_wszystkich_danych = self.df.shape[0]\n",
    "        braki = self.df.isnull().sum()\n",
    "        procent_brakow = (braki/ilosc_wszystkich_danych)*100\n",
    "        do_usuniecia = pd.DataFrame({\n",
    "            'Liczba brakow':braki,\n",
    "            'procent': procent_brakow\n",
    "        }).sort_values(by='procent',ascending=False)\n",
    "        do_usuniecia['Do Usuniecia'] = do_usuniecia['procent']>30\n",
    "        do_usuniecia_kolumny = do_usuniecia[do_usuniecia['Do Usuniecia']==True].index.tolist()\n",
    "        print(f\"Kolumny do usuniecia {do_usuniecia_kolumny}\")\n",
    "    def przygotowanie_danych(self):\n",
    "        usuwanie = [['salary_range','required_education', 'benefits', 'required_experience', 'function']]\n",
    "        self.df.drop(columns=usuwanie, inplace=True, errors='ignore')\n",
    "        self.df['required_experience'].fillna('Not Specified', inplace=True)\n",
    "        self.df['department'].fillna('Unknown', inplace=True)\n",
    "        for col in self.df.select_dtypes(include='object').columns:\n",
    "            if col != 'fraudulent':  \n",
    "                self.df[col] = self.df[col].astype(str) \n",
    "                le = LabelEncoder()\n",
    "                self.df[col] = le.fit_transform(self.df[col])\n",
    "        print(f\"Dane zostały przygotowane\")\n",
    "    def dane(self):\n",
    "        self.X = self.df.drop([\"fraudulent\"],axis=1)\n",
    "        self.y = self.df[\"fraudulent\"]\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
    "    def wybierz_najlepszy_model(self):\n",
    "        modele = {\n",
    "             \"XGBoost\": XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, n_jobs=-1, eval_metric='mlogloss'),\n",
    "            \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "            \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=50, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "            \"Neural Network\": MLPClassifier(hidden_layer_sizes=100, max_iter=500, random_state=42)\n",
    "        }\n",
    "    \n",
    "        najlepszy_model = None\n",
    "        najlepsza_dokladnosc = 0\n",
    "        for model_nazwa, model in modele.items():\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            accuracy = model.score(self.X_test, self.y_test)\n",
    "            print(f\"Model {model_nazwa}: {accuracy: .2f}\")\n",
    "            if accuracy > najlepsza_dokladnosc:\n",
    "                najlepsza_dokladnosc = accuracy\n",
    "                najlepszy_model = model\n",
    "        self.model = najlepszy_model\n",
    "        \n",
    "        \n",
    "        \n",
    "    def trenowanie(self):\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "    def predict(self):\n",
    "        y_pred=self.model.predict(self.X_test)\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        print(f\"Dokładnosc modelu to : {accuracy:.2f}\")\n",
    "        scores = cross_val_score(self.model, self.X_train, self.y_train, cv=5, scoring='accuracy')\n",
    "        print(f\"Średnia dokładnosc: {np.mean(scores):.2f}\")\n",
    "\n",
    "\n",
    "model = Predykcja(\"DataSets/fake_job_postings.csv\")\n",
    "model.EDA()\n",
    "model.kolumny_do_usuniecia()\n",
    "model.przygotowanie_danych()\n",
    "model.dane()\n",
    "model.wybierz_najlepszy_model()\n",
    "model.trenowanie()\n",
    "model.predict()\n",
    "\n"
   ],
   "id": "52278b55ffedb35e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17880 entries, 0 to 17879\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   job_id               17880 non-null  int64 \n",
      " 1   title                17880 non-null  object\n",
      " 2   location             17534 non-null  object\n",
      " 3   department           6333 non-null   object\n",
      " 4   salary_range         2868 non-null   object\n",
      " 5   company_profile      14572 non-null  object\n",
      " 6   description          17879 non-null  object\n",
      " 7   requirements         15185 non-null  object\n",
      " 8   benefits             10670 non-null  object\n",
      " 9   telecommuting        17880 non-null  int64 \n",
      " 10  has_company_logo     17880 non-null  int64 \n",
      " 11  has_questions        17880 non-null  int64 \n",
      " 12  employment_type      14409 non-null  object\n",
      " 13  required_experience  10830 non-null  object\n",
      " 14  required_education   9775 non-null   object\n",
      " 15  industry             12977 non-null  object\n",
      " 16  function             11425 non-null  object\n",
      " 17  fraudulent           17880 non-null  int64 \n",
      "dtypes: int64(5), object(13)\n",
      "memory usage: 2.5+ MB\n",
      "Informacje o danych None\n",
      "Shape (17880, 18)\n",
      "Liczba braków w danych job_id                     0\n",
      "title                      0\n",
      "location                 346\n",
      "department             11547\n",
      "salary_range           15012\n",
      "company_profile         3308\n",
      "description                1\n",
      "requirements            2695\n",
      "benefits                7210\n",
      "telecommuting              0\n",
      "has_company_logo           0\n",
      "has_questions              0\n",
      "employment_type         3471\n",
      "required_experience     7050\n",
      "required_education      8105\n",
      "industry                4903\n",
      "function                6455\n",
      "fraudulent                 0\n",
      "dtype: int64\n",
      "Kolumny do usuniecia ['salary_range', 'department', 'required_education', 'benefits', 'required_experience', 'function']\n",
      "Dane zostały przygotowane\n",
      "Model XGBoost:  0.98\n",
      "Model Random Forest:  0.97\n",
      "Model Gradient Boosting:  0.97\n",
      "Model Neural Network:  0.94\n",
      "Dokładnosc modelu to : 0.98\n",
      "Średnia dokładnosc: 0.98\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f22126cb90d8481b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
